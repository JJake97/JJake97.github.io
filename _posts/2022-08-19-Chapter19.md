---
published: true
layout: single
title: 'Generative Models I'
categories: CV
tag: Pytorch
toc: true
author_profile: false
sidebar:
  nav: 'docs'
---


# Generative Models I

## Supervised VS Unsupervised Learning

### Supervised learning

- Classification, Object detection, Semantic segmentation 등에 사용되는 학습 방법
- 지도학습은 학습데이터의 Label, 정답이 주어진 학습법
- 주어진 데이터와 그 label을 학습하며 새로운 data와 그에 따른 label을 mapping하는 함수를 찾는 학습 방법

### Unsupervised learning

- Clustering, Demensionality reduction, Feature learning, Density estimation 등에 사용되는 학습 방법
- 정답 label이 주어지지 않고 데이터의 분포와 특징을 잘 포착해 결과물을 도출하는 학습 방법
- label이 없기 때문에, data의 hidden structure를 찾아내는 것이 목표라고 할 수 있음

## Discriminative VS Generative Models

### Discriminative models

- 일반적이고 직관적인 머신러닝 모델의 종류
- 데이터 X가 주어졌을 때 레이블 Y가 나타날 조건부확률을 직접적으로 반환하는 모델
- label의 정보가 필요한 지도학습에 속하며, X의 label을 잘 구분하는 Decision boundary를 학습하는 것이 목표가 됨
- 그러나 데이터 X가 완전히 새로운 데이터여도 모델은 기존의 label 내에서만 분류를 진행하기 때문에 아래 그림과 같은 이상한 결과가 도출될 수 있음

![1](/assets/image_ch19/1.png)

### Generative models

- Discriminative model과 달리 X가 발생할 확률인 P(X)나 사전확률을 명시적으로 계산하는 모델
- 이 계산된 확률 정보를 이용하여 새로운 데이터를 생성할 수 있음
- Baye's Rule을 활용하여 사후확률을 학습할 수 있음

![2](/assets/image_ch19/2.png)


### Taxonomy of Generative Models

- 생성 모델의 세부 특징에 따라 아래 그림과 같이 분류해볼 수 있음

![3](/assets/image_ch19/3.png)

#### Explicit density

- P(x)가 어떤 분포를 나타내는지 정의하고 찾는것에 초점을 두는 것
- Training data의 likelihood를 높이는 방향으로 학습을 진행함
- x1에서 xi까지가 각 pixel이 등장할 확률이라면, 해당 pixel들로 구성된 이미지가 나타날 확률은 각 pixel들의 확률곱으로 나타낼 수 있고, Loss 또한 계산이 가능하여 학습 정도를 알 수 있음
- 아래 식으로 표현이 되며, PixelRNN이 이 방식을 사용한 예시임

![4](/assets/image_ch19/4.png)

#### Pixel RNN

![5](/assets/image_ch19/5.png)

- 왼쪽 위 코너의 시작점으로부터 상하좌우로 뻗어나가면서 이미지를 pixel by pixel로 생성하는 모델
- 이때 새로 만들어지는 픽셀은 인접한 픽셀들의 영향을 받아서 새로 생성됨
- 이전 결과에 영향을 받는 구조에는 RNN이 적합하기 때문에 이전 픽셀들에 대한 Dependency는 LSTM같은 RNN기반 모델등으로 표현이 됨
- 그러나 이 생성작업을 모든 픽셀에 대해 순차적으로 반복적으로 해야하기 때문에 매우 느린 단점이 존재함

#### Pixel CNN

![6](/assets/image_ch19/6.png)
- RNN구조를 CNN구조로 대체한 모델
- CNN구조의 특성상 주변 pixel을 동시에 살펴볼 수 있기때문에 계산이 빠름

### Variational Autoencoders

- VAE는 Intractable density function이기 때문에 직접적인 계산을 통해 최적화를 진행할 수 없음
- Funciton의 하한선을 찾아서 그 하한선을 Maximize하는 방법으로 최적화를 대신함

#### Autoencoder
- label이 없는 데이터에서 Feature representation을 뽑는 비지도 학습법

1. Input data X에서 Feature vector z를 추출
    - x에서 의미있는 요소를 추출한 것이 z이기 때문에 대체적으로 z의 demension이 x보다 작음
    
2. Feature z에서 Reconstructed input data를 다시 생성
    - Loss를 최소화하는 방향으로 학습이 진행되며, 이후 Decoder를 제거하게되면 Encoder에 의한 Feature representation이 완성됨
    
![7](/assets/image_ch19/7.png)

### Variational Autoencoders

![8](/assets/image_ch19/8.png)

- VAE는 AE로 추출된 feature를 사용하여 새로운 이미지를 생성할 수 없을까?라는 의문에서 출발한 모델
- Encoder : X를 input으로 받아서 mean, covariance를 추출하고 z space상에서 분포를 생성, z는 gaussian 분포를 따른다고 가정(다른 분포도 가능)
- Decoder : gaussian 분포로부터 z를 sampling, sampling한 z를 가지고 decoder는 x space상의 확률분포를 생성하고 x를 이 분포로부터 sampling
- 결과적으로 유의미한 feature vector z를 얻을 수 있음
